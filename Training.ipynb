{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNjhHulWm6pQViofd36ZoeJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hieunguyen-cyber/AI_Project_CBH_GHHKM/blob/main/Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Huấn luyện mô hình nhận diện biển báo giao thông sử dụng YOLOv10**\n",
        "\n",
        "\n",
        "\n",
        "Nhóm thực hiện: CBH_GHHKM\n",
        "\n",
        "**Lưu ý**: Trước khi thực hiện, chuyển đổi môi trường chạy sang GPU\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-VILZAAlD4UQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Bước 1**: Clone các file cần thiết\n",
        "\n",
        "Ở đây, YOLOv10 sẽ được clone từ GitHub và tập dữ liệu sử dụng để huấn luyện sẽ được tải về sử dụng API từ Kaggle.\n",
        "\n",
        "Nguồn:\n",
        "* [Vietnamese Traffic Signs Dataset](https://www.kaggle.com/datasets/maitam/vietnamese-traffic-signs)\n",
        "* [YOLOv10](https://github.com/THU-MIG/yolov10)"
      ],
      "metadata": {
        "id": "8lTAN7GeER2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUAGjFPHBTW5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed3ef206-cc7f-4d40-f3f2-8d93574d7bc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'API-key'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n",
            "Cloning into 'yolov10'...\n",
            "remote: Enumerating objects: 20329, done.\u001b[K\n",
            "remote: Counting objects: 100% (1527/1527), done.\u001b[K\n",
            "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
            "remote: Total 20329 (delta 1450), reused 1363 (delta 1351), pack-reused 18802\u001b[K\n",
            "Receiving objects: 100% (20329/20329), 11.19 MiB | 20.87 MiB/s, done.\n",
            "Resolving deltas: 100% (14326/14326), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hieunguyen-cyber/API-key.git\n",
        "!git clone https://github.com/THU-MIG/yolov10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Bước 2**: Tiến hành tải về tập dữ liệu\n",
        "\n",
        "Ở đây tôi đã thêm 1 file **sign.yaml** vào tập dữ liệu gốc nhằm phục vụ cho việc huấn luyện."
      ],
      "metadata": {
        "id": "ps6KSMm7HE12"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/API-key/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!pip install -q kaggle\n",
        "!kaggle datasets download -d hieunguyen2208/vietnamese-traffic-signs"
      ],
      "metadata": {
        "collapsed": true,
        "id": "h3ViZy9_F7jW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f83fae-4ade-430e-b435-58e807698181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/hieunguyen2208/vietnamese-traffic-signs\n",
            "License(s): Apache 2.0\n",
            "Downloading vietnamese-traffic-signs.zip to /content\n",
            "100% 756M/757M [00:13<00:00, 133MB/s] \n",
            "100% 757M/757M [00:13<00:00, 59.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tiến hành giải nén tập dữ liệu"
      ],
      "metadata": {
        "id": "mkYVf0vVIMWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/vietnamese-traffic-signs.zip"
      ],
      "metadata": {
        "id": "IF0MxMIVIQc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Bước 3**: Tiến hành cài đặt YOLOv10\n",
        "\n",
        "**Lưu ý**: Do lỗi dependencies giữa một vài thư viện của PyTorch nên bước này chạy hai lần"
      ],
      "metadata": {
        "id": "MMpNLXD7IT3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd yolov10\n",
        "!pip install torch\n",
        "!pip install -q -r requirements.txt\n",
        "!pip install -e\n",
        "!wget https://github.com/THU-MIG/yolov10/releases/download/v1.1/yolov10n.pt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "D8DUp76EIfdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b90691b-c170-49cf-9307-003a73b25fd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov10\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Bước 4**: Tiến hành chia tập dư liệu thành tập train và val\n",
        "\n",
        "Cụ thể, tập dữ liệu gốc gồm 3216 cặp image-label, ta chia thành hai tập, tập train gồm 2572 cặp, tập val gồm 644 cặp"
      ],
      "metadata": {
        "id": "pt7_AajLJhQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "image_dir = '/content/dataset/images'\n",
        "label_dir = '/content/dataset/labels'\n",
        "train_image_dir = '/content/dataset/images/train'\n",
        "val_image_dir = '/content/dataset/images/val'\n",
        "train_label_dir = '/content/dataset/labels/train'\n",
        "val_label_dir = '/content/dataset/labels/val'\n",
        "\n",
        "os.makedirs(train_image_dir, exist_ok=True)\n",
        "os.makedirs(val_image_dir, exist_ok=True)\n",
        "os.makedirs(train_label_dir, exist_ok=True)\n",
        "os.makedirs(val_label_dir, exist_ok=True)\n",
        "\n",
        "images = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "labels = [f.replace('.jpg', '.txt') for f in images]\n",
        "\n",
        "if len(images) == 0:\n",
        "    raise ValueError(\"No images found in the dataset directory.\")\n",
        "if len(images) < 5:\n",
        "    raise ValueError(\"Not enough samples to split. Ensure you have at least 5 images.\")\n",
        "\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    images, labels, test_size=0.2, train_size=0.8, random_state=42\n",
        ")\n",
        "\n",
        "for img, lbl in zip(train_images, train_labels):\n",
        "    shutil.move(os.path.join(image_dir, img), os.path.join(train_image_dir, img))\n",
        "    shutil.move(os.path.join(label_dir, lbl), os.path.join(train_label_dir, lbl))\n",
        "\n",
        "for img, lbl in zip(val_images, val_labels):\n",
        "    shutil.move(os.path.join(image_dir, img), os.path.join(val_image_dir, img))\n",
        "    shutil.move(os.path.join(label_dir, lbl), os.path.join(val_label_dir, lbl))\n"
      ],
      "metadata": {
        "id": "bg0v-fOnKGK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Bước 5**: Tiến hành huấn luyện\n",
        "\n",
        "Ở đây, do hạn chế về mặt phần cứng và để tiết kiệm thời gian huấn luyện, đội quyết định chọn các thông số như sau:\n",
        "* EPOCHS = 200\n",
        "* BATCH_SIZE = 256\n",
        "* IMAGE_SIZE = 320\n",
        "Sau đó, file trọng số **best.pt** được trích xuất và huấn luyện lại nhiều lần với thông số mỗi lần là:\n",
        "* EPOCHS = 50\n",
        "* BATCH_SIZE = 256\n",
        "* IMAGE_SIZE = 320\n",
        "Cụ thể, với kích cỡ của tập dữ liệu như trên, thời gian huấn luyện 1 epoch trung bình mất 2 phút. Tổng thời gian huấn luyện khoảng 60 phút."
      ],
      "metadata": {
        "id": "YdlNFI_WMgwE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLOv10\n",
        "MODEL_PATH = '/content/yolov10/yolov10n.pt'\n",
        "model = YOLOv10(MODEL_PATH)\n",
        "YAML_PATH = '/content/dataset/sign.yaml'\n",
        "EPOCHS = 50\n",
        "IMG_SIZE = 320\n",
        "BATCH_SIZE = 256\n",
        "model.train(data=YAML_PATH ,\n",
        "            epochs= EPOCHS ,\n",
        "            batch=BATCH_SIZE,\n",
        "            imgsz= IMG_SIZE)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KUtU9tOINaTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Bước 6**: Lưu file trọng số về máy\n",
        "\n",
        "Tiến hành lưu file trọng số **best.pt** để tiến hành sử dụng trong bài toán nhận diện biển báo giao thông trong file **Prediction**"
      ],
      "metadata": {
        "id": "77z0HAtYckhY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "file_path = '/content/yolov10/runs/detect/train/weights/best.pt'\n",
        "files.download(file_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "XKx6QocYc-H-",
        "outputId": "d90af7e7-2d99-4e25-8ca3-a20dcfa6bd2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7e1db5f5-a5db-421d-9341-9b365260083e\", \"best.pt\", 5754745)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}