{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hieunguyen-cyber/AI_Project_CBH_GHHKM/blob/main/Predicting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5UMSnbwTSBo"
      },
      "source": [
        "#**Sử dụng mô hình YOLOv10 đã được huấn luyện để nhận diện biên báo giao thông**\n",
        "\n",
        "\n",
        "Ở đây, chúng ta sẽ sử dụng file trọng số **best.pt** thu được trong giai đoạn huấn luyện để áp dụng vào mô hình YOLOv10 nhằm giải quyết bài toán nhận diện biển báo giao thông.\n",
        "\n",
        "**Chú ý**: Kết nối với GPU trước khi sử dụng\n",
        "\n",
        "Nhóm thực hiện: CBH_GHHKM\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNw_R4VrUyK5"
      },
      "source": [
        "###**Bước 1**: Tải file trọng số **best.pt** lên Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr3MYmZYVKPu"
      },
      "source": [
        "* Trong trường hợp file trọng số được lưu nội bộ trong máy tính"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbdbHrIPTADA"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_QVz094WbDv"
      },
      "source": [
        "* Trong trường hợp muốn sử dụng file trọng số có sẵn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-rUHubbWf4t",
        "outputId": "aeaa3626-e309-421f-bc4d-863354a43e15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Weight_AIBK_2024'...\n",
            "remote: Enumerating objects: 8, done.\u001b[K\n",
            "remote: Counting objects: 100% (8/8), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 8 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (8/8), 9.90 MiB | 23.86 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hieunguyen-cyber/Weight_AIBK_2024.git\n",
        "!mv /content/Weight_AIBK_2024/best.pt /content"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5MlDFuYW5JSs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Bước 2**: Tải dữ liệu muốn dự đoán\n",
        "\n",
        "Để các ảnh cần dự đoán trong 1 folder tên **test_img** trong Google Drive"
      ],
      "metadata": {
        "id": "eGQ95A1B5Lh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqMjDK705S8r",
        "outputId": "7c64cebe-0e54-4504-9f46-f15250579a34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSTJTMvUgsuo"
      },
      "source": [
        "###**Bước 3**: Cài đặt YOLOv10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SiCPU4Uwgoij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "411f31e6-7ad4-4a70-9b67-9ef73bb714f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov10'...\n",
            "remote: Enumerating objects: 20329, done.\u001b[K\n",
            "remote: Counting objects: 100% (1527/1527), done.\u001b[K\n",
            "remote: Compressing objects: 100% (176/176), done.\u001b[K\n",
            "remote: Total 20329 (delta 1450), reused 1363 (delta 1351), pack-reused 18802\u001b[K\n",
            "Receiving objects: 100% (20329/20329), 11.19 MiB | 15.67 MiB/s, done.\n",
            "Resolving deltas: 100% (14326/14326), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/THU-MIG/yolov10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Bước 4**: Tiến hành dự đoán"
      ],
      "metadata": {
        "id": "rHT3GDia6QHR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change to the directory where your model and images are located\n",
        "%cd /content/yolov10\n",
        "\n",
        "from ultralytics import YOLOv10\n",
        "import os\n",
        "\n",
        "# Initialize the YOLOv10 model\n",
        "MODEL_PATH = '/content/best.pt'\n",
        "model = YOLOv10(MODEL_PATH)\n",
        "\n",
        "# Define the input and output folders\n",
        "input_folder = '/content/drive/MyDrive/test_img'\n",
        "output_folder = '/content/output_images'\n",
        "\n",
        "# Create output directory if it doesn't exist\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Process each image in the input folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
        "        input_path = os.path.join(input_folder, filename)\n",
        "\n",
        "        # Perform inference on the image\n",
        "        results = model.predict(input_path)\n",
        "\n",
        "        # Save the result images to the output folder\n",
        "        output_path = os.path.join(output_folder, filename)\n",
        "        results[0].save(output_path)\n",
        "\n",
        "        print(f'Processed and saved: {output_path}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ru5IwVpF6T7b",
        "outputId": "47859410-972c-4761-c20b-54e81191441a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov10\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/test_img/th (1).jpeg: 224x320 1 Lane Allocation, 64.3ms\n",
            "Speed: 1.1ms preprocess, 64.3ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n",
            "Processed and saved: /content/output_images/th (1).jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/test_img/0016.jpg: 192x320 1 No Stopping and No Parking, 58.0ms\n",
            "Speed: 1.0ms preprocess, 58.0ms inference, 1.2ms postprocess per image at shape (1, 3, 192, 320)\n",
            "Processed and saved: /content/output_images/0016.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/test_img/pop.jpeg: 224x320 3 No Stopping and No Parkings, 59.4ms\n",
            "Speed: 1.0ms preprocess, 59.4ms inference, 1.2ms postprocess per image at shape (1, 3, 224, 320)\n",
            "Processed and saved: /content/output_images/pop.jpeg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/test_img/bien-bao-1.jpg: 256x320 (no detections), 77.8ms\n",
            "Speed: 1.2ms preprocess, 77.8ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 320)\n",
            "Processed and saved: /content/output_images/bien-bao-1.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/test_img/Bien-bao-giao-thong.jpg: 224x320 (no detections), 58.8ms\n",
            "Speed: 1.2ms preprocess, 58.8ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n",
            "Processed and saved: /content/output_images/Bien-bao-giao-thong.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/test_img/ung-dung-bien-bao-giao-thong.jpg: 224x320 2 Speed limit (40km/h)s, 69.1ms\n",
            "Speed: 1.5ms preprocess, 69.1ms inference, 1.1ms postprocess per image at shape (1, 3, 224, 320)\n",
            "Processed and saved: /content/output_images/ung-dung-bien-bao-giao-thong.jpg\n",
            "\n",
            "image 1/1 /content/drive/MyDrive/test_img/cd62724a-20190806_040028.jpg: 256x320 1 Speed limit (80km/h), 75.9ms\n",
            "Speed: 1.2ms preprocess, 75.9ms inference, 1.1ms postprocess per image at shape (1, 3, 256, 320)\n",
            "Processed and saved: /content/output_images/cd62724a-20190806_040028.jpg\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyOb++7vtVUdiAKJhZOuAHKb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}